{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import savgol_filter\n",
    "\n",
    "window_length = 60\n",
    "polyorder = 3\n",
    "\n",
    "def correlation(df, index, rows):\n",
    "    x = df.iloc[:, index].values\n",
    "    y = df.iloc[:, (index + 1)%rows].values\n",
    "    return np.corrcoef(x, y)[0, 1]\n",
    "\n",
    "def features(df):\n",
    "    X = [[\"mean\"], [\"std\"], [\"corelation\"], [\"zero cross\"], [\"max\"], [\"min\"], [\"skewness\"], [\"kurtosis\"], [\"p2p time\"], [\"median\"], [\"25th percentile\"], [\"75th percentile\"], [\"range\"], [\"mode\"], [\"cover\"], [\"IQR\"], [\"square mean\"]]\n",
    "    for i in range(len(df.T)):\n",
    "        x = savgol_filter(df.iloc[:, i].values, window_length = window_length, polyorder = polyorder)\n",
    "        X[0].extend([np.mean(x)])\n",
    "        X[1].extend([np.std(x)])\n",
    "        X[2].extend([correlation(df, i, len(df.T))])\n",
    "        X[3].extend([np.sum(np.diff(np.sign(x)) != 0)])\n",
    "        X[4].extend([np.max(x)])\n",
    "        X[5].extend([np.min(x)])\n",
    "        X[6].extend([stats.skew(x)])\n",
    "        X[7].extend([stats.kurtosis(x)])\n",
    "        X[8].extend([abs(np.argmax(x) - np.argmin(x))])\n",
    "        X[9].extend([np.median(x)])\n",
    "        X[10].extend([np.percentile(x, 25)])\n",
    "        X[11].extend([np.percentile(x, 75)])\n",
    "        X[12].extend([np.max(x) - np.min(x)])\n",
    "        X[13].extend([stats.mode(x)[0]])\n",
    "        X[14].extend([np.std(x) / np.mean(x)])\n",
    "        X[15].extend([np.percentile(x, 75) - np.percentile(x, 25)])\n",
    "        X[16].extend([np.mean(x**2)])\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for axis in X:\n",
    "        features.extend(axis[1:])\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = listdir(\"../data\")\n",
    "\n",
    "columns = [(0, 80), (15, 95), (5, 85), (5, 55), (5, 85), (5, 85)]\n",
    "\n",
    "for index, folder in enumerate(folders):\n",
    "    open(f\"../test_features/{folder}.csv\", \"w\").close()\n",
    "\n",
    "    files = listdir(f\"../data/{folder}\")[:17]\n",
    "    \n",
    "    for file in files:\n",
    "        data = pd.read_csv(f\"../data/{folder}/{file}\", header=None).iloc[columns[0][0]:columns[0][1], :6]\n",
    "        feature = features(data.iloc[:, 0:3])\n",
    "        feature.extend(features(data.iloc[:, 3:6]))\n",
    "\n",
    "        pd.DataFrame(feature).T.to_csv(f\"../test_features/{folder}.csv\", header = None, index = False, mode = \"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing features using avg std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from os import listdir\n",
    "\n",
    "classes = listdir(\"../test_features\")\n",
    "\n",
    "features = [pd.read_csv(f\"../test_features/{file}\", header=None) for file in classes]\n",
    "\n",
    "type = [\"accl\", \"gyro\"]\n",
    "X = [[\"max m\"], [\"min m\"], [\"imag\"], [\"imag mean\"], [\"100 th percentile\"], [\"iqr\"], [\"range\"], [\"std\"], [\"half mean\"], [\"half median\"], [\"half 70th percentile\"]]\n",
    "\n",
    "class_std = []\n",
    "avg_std = []\n",
    "\n",
    "for i in range(17):\n",
    "    feature = [data[i] for data in features]\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        feature = np.where(np.ptp(feature) != 0, (feature - np.min(feature)) / np.ptp(feature), feature)\n",
    "\n",
    "    median = []\n",
    "    std = []\n",
    "    for j in range(len(classes)):\n",
    "        median.append(np.median(feature[j]))\n",
    "        std.append(np.round(np.std(feature[j]), 3)*1000)\n",
    "        class_std.append(np.round(np.std(median),3)*1000)\n",
    "    avg_std.append(np.average(std))\n",
    " \n",
    "for i in range(17):\n",
    "    feature = [data[i] for data in features]\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        feature = np.where(np.ptp(feature) != 0, (feature - np.min(feature)) / np.ptp(feature), feature)\n",
    "\n",
    "    for j in range(len(classes)):\n",
    "        plt.scatter(feature[j], [classes[j][:-4]]*len(features[j]), label = str(np.round(np.std(feature[j]), 3)*1000))\n",
    "    plt.legend()\n",
    "    plt.title(\"{0} {1} {2}   {3}\".format(type[(i//3)//len(X)], X[(i//3)%len(X)][0], i%3 + 1, np.round(np.std(median),3)*1000))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation(df, index, rows):\n",
    "    x = df.iloc[:, index].values\n",
    "    y = df.iloc[:, (index + 1)%rows].values\n",
    "    return np.corrcoef(x, y)[0, 1]\n",
    "\n",
    "def features1(df):\n",
    "    X = [[\"std\"], [\"max\"], [\"min\"], [\"range\"], [\"mode\"]]\n",
    "    for i in range(len(df.T)):\n",
    "        x = df.iloc[:, i].values\n",
    "        # X[0].extend([np.mean(x)])\n",
    "        X[0].extend([np.std(x)])\n",
    "        # X[2].extend([correlation(df, i, len(df.T))])\n",
    "        # X[3].extend([np.sum(np.diff(np.sign(x)) != 0)])\n",
    "        X[1].extend([np.max(x)])\n",
    "        X[2].extend([np.min(x)])\n",
    "        # X[6].extend([stats.skew(x)])\n",
    "        # X[7].extend([stats.kurtosis(x)])\n",
    "        # X[8].extend([abs(np.argmax(x) - np.argmin(x))])\n",
    "        # X[3].extend([np.median(x)])\n",
    "        # X[10].extend([np.percentile(x, 25)])\n",
    "        # X[4].extend([np.percentile(x, 75)])\n",
    "        X[3].extend([np.max(x) - np.min(x)])\n",
    "        X[4].extend([stats.mode(x)[0]])\n",
    "        # X[14].extend([np.std(x) / np.mean(x)])\n",
    "        # X[7].extend([np.percentile(x, 75) - np.percentile(x, 25)])\n",
    "        # X[8].extend([np.mean(x**2)])\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for axis in X:\n",
    "        features.extend(axis[1:])\n",
    "    \n",
    "    return features\n",
    "\n",
    "def features2(df):\n",
    "    X = [[\"max\"], [\"min\"], [\"range\"]]\n",
    "    for i in range(len(df.T)):\n",
    "        x = df.iloc[:, i].values\n",
    "        # X[0].extend([np.mean(x)])\n",
    "        # X[1].extend([np.std(x)])\n",
    "        # X[2].extend([correlation(df, i, len(df.T))])\n",
    "        # X[3].extend([np.sum(np.diff(np.sign(x)) != 0)])\n",
    "        X[0].extend([np.max(x)])\n",
    "        X[1].extend([np.min(x)])\n",
    "        # X[6].extend([stats.skew(x)])\n",
    "        # X[7].extend([stats.kurtosis(x)])\n",
    "        # X[8].extend([abs(np.argmax(x) - np.argmin(x))])\n",
    "        # X[3].extend([np.median(x)])\n",
    "        # X[4].extend([np.percentile(x, 25)])\n",
    "        # X[11].extend([np.percentile(x, 75)])\n",
    "        X[2].extend([np.max(x) - np.min(x)])\n",
    "        # X[13].extend([stats.mode(x)[0]])\n",
    "        # X[14].extend([np.std(x) / np.mean(x)])\n",
    "        # X[15].extend([np.percentile(x, 75) - np.percentile(x, 25)])\n",
    "        # X[16].extend([np.mean(x**2)])\n",
    "\n",
    "    features = []\n",
    "\n",
    "    for axis in X:\n",
    "        features.extend(axis[1:])\n",
    "    \n",
    "    return features\n",
    "\n",
    "folders = listdir(\"../data\")\n",
    "\n",
    "columns = [(0, 50), (15, 65), (0, 50), (5, 55), (0, 50), (0, 50)]\n",
    "\n",
    "for index, folder in enumerate(folders):\n",
    "    open(f\"../features/{folder}.csv\", \"w\").close()\n",
    "\n",
    "    files = listdir(f\"../data/{folder}\")[:17]\n",
    "    \n",
    "    for file in files:\n",
    "        data = pd.read_csv(f\"../data/{folder}/{file}\", header=None).iloc[columns[index][0]:columns[index][1], :6]\n",
    "        feature = features1(data.iloc[:, 0:3])\n",
    "        feature.extend(features2(data.iloc[:, 3:6]))\n",
    "\n",
    "        pd.DataFrame(feature).T.to_csv(f\"../features/{folder}.csv\", header = None, index = False, mode = \"a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import listdir\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_X_y(path):\n",
    "    folder = listdir(path)\n",
    "    X = []\n",
    "    y = []\n",
    "    for index, file in enumerate(folder):\n",
    "        df = pd.read_csv(f\"{path}/{file}\", header = None)\n",
    "        X.extend(df.values)\n",
    "        y.extend([index]*len(df))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = csv_to_X_y('../test_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96.07843137254902\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, random_state=10, test_size=0.2)\n",
    "\n",
    "model = svm.SVC()\n",
    "\n",
    "history = model.fit(X_train,y_train)\n",
    "\n",
    "print(accuracy_score(model.predict(X),y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-9.93443049e+02,  0.00000000e+00,  2.20429433e+03,  7.31633588e+03,\n",
       "        6.58005976e+03,  6.13419123e+02,  6.09746264e+02,  1.17084150e+03,\n",
       "        1.59011457e+03, -6.38988404e+00, -2.53058041e+01, -2.29993233e+00,\n",
       "       -1.11718635e+01,  7.71630481e-01,  1.33014394e+00,  2.33785002e+00,\n",
       "        7.54880196e-01,  4.67027644e-01,  5.12281867e-01])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 5.27688497, -0.21931466,  0.75370862,  3.10086833,  1.78151193,\n",
       "         4.18943908]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.decision_function([X[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../test.joblib']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "joblib.dump(model, \"../test.joblib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "test"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
